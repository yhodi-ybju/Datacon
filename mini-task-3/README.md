# Мини‑таск 3: Обучение моделей для предсказания биологической активности

В этом задании вы переходите к построению моделей машинного обучения для предсказания биологической активности малых молекул. Используя набор дескрипторов, полученный на предыдущем этапе, вы обучите и сравните различные типы моделей.

## Цель

Построить, обучить и сравнить несколько моделей, способных предсказывать активность молекул (IC50 или pIC50) на основе их структурных признаков. Оценить эффективность различных подходов, наборов дескрипторов и архитектур, сделать выводы и предложения по улучшению.



## Что нужно сделать

### 1. Подготовка данных

- Используйте один или несколько файлов с дескрипторами, полученных в мини‑таске 2.
- Выполните нормализацию/стандартизацию признаков:
  - возможно использование `MinMaxScaler`, `StandardScaler`, логарифмические преобразования и др.;
  - если необходимо, можно логарифмировать целевую переменную (`standard_value` → `pIC50`).
- При желании можно уменьшить размерность пространства признаков с помощью:
  - `PCA` (главные компоненты),
  - `t-SNE`, `UMAP` (для визуализации/исследования структуры).

> Конкретный выбор метода и параметров остается за вами — он должен быть обоснован в ноутбуке.

### 2. Обучение моделей

Обучите не менее **четырёх** различных моделей:

- **Две классические модели машинного обучения**, например:
  - `Random Forest Regressor`,
  - `Gradient Boosting`, `XGBoost`, `LightGBM` или аналогичные;
- **Две нейросетевые модели**:
  - полносвязная сеть (`MLP`);
  - сверточная сеть (`CNN`).

Каждая модель должна быть обучена на одних и тех же данных для корректного сравнения.

> Архитектура нейросетей подбирается самостоятельно. Можно использовать PyTorch, Keras, TensorFlow или другие фреймворки.

### 3. Воспроизводимость и стабильность

- Установите `random_seed` для всех библиотек, чтобы обеспечить воспроизводимость.
- Проверьте стабильность результатов:
  - с помощью **кросс-валидации** (например, KFold);
  - или путём повторного обучения с различными `random_state`.

> Желательно сравнить не только средние метрики, но и разброс (дисперсию) результатов.

### 4. Сравнение результатов

Сравните модели по следующим аспектам:

- метрики (например, `MAE`, `RMSE`, `R²`);
- скорость обучения, интерпретируемость, переобучение;
- чувствительность к типу дескрипторов;
- необходимость предобработки или отбора признаков.

> Сделайте выводы, какие комбинации (модель + дескрипторы) работают лучше всего, и почему.



## Что нужно сдать

- Jupyter Notebook (`.ipynb`), содержащий:
  - код по подготовке данных, обучению моделей, сравнению результатов;
  - графики/таблицы с метриками и выводами;
  - обоснование выбора архитектур, признаков, параметров;
- (по желанию) отдельные `.csv`/`.json` файлы с метриками, логами, сохранёнными моделями.
